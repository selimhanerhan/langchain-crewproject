from shortGPT.config.api_db import ApiKeyManager, ApiProvider
from shortGPT.config.asset_db import AssetDatabase, AssetType
from shortGPT.engine.content_video_engine import ContentVideoEngine
from shortGPT.engine.facts_short_engine import FactsShortEngine
from shortGPT.audio.eleven_voice_module import ElevenLabsVoiceModule
from shortGPT.config.languages import Language
from shortGPT.audio.edge_voice_module import EdgeTTSVoiceModule, EDGE_TTS_VOICENAME_MAPPING
import ssl
import urllib.request





ssl._create_default_https_context = ssl._create_unverified_context

class ContentVideoEnginee:
    def __init__(self):
        pass

    def generate_content(self, script):
        AssetDatabase.add_remote_asset("background", AssetType.BACKGROUND_VIDEO,
                                       "https://www.youtube.com/watch?v=hPpGlBQnxbE")
        AssetDatabase.add_remote_asset('chill music', AssetType.BACKGROUND_MUSIC,
                                       "https://www.youtube.com/watch?v=uUu1NcSHg2E")
        AssetDatabase.add_local_asset('my_music', AssetType.AUDIO, "./my_music.wav")

        USE_ELEVEN_LABS = False
        # Configure the ElevenLabs Voice Module
        if USE_ELEVEN_LABS:
            eleven_labs_key = ApiKeyManager.get_api_key(ApiProvider.ELEVEN_LABS)
            voice_module = ElevenLabsVoiceModule(api_key=eleven_labs_key, voiceName="Antoni")
        else:
            ## You can also use the EdgeTTS for Free voice synthesis
            voice_name = EDGE_TTS_VOICENAME_MAPPING[Language.ENGLISH]['male']
            voice_module = EdgeTTSVoiceModule(voice_name)

        # Configure Content Engine
        content_engine = FactsShortEngine(voiceModule=voice_module,
                                          facts_type=script,
                                          background_video_name="background",
                                          # <--- use the same name you saved in  the AssetDatabase
                                          background_music_name='chill music',
                                          # <--- use the same name you saved in  the AssetDatabase
                                          num_images=5,  # If you don't want images in your video, put 0 or None
                                          language=Language.ENGLISH)

        # Generate Content
        for step_num, step_logs in content_engine.makeContent():
            print(f" {step_logs}")

        # Get Video Output Path
        print(content_engine.get_video_output_path())

    def read_txt_file(self, filename):
        with open(filename, "r") as txt_file:
            file_contents = txt_file.read()
        return file_contents

if __name__ == "__main__":
    ApiKeyManager.set_api_key(ApiProvider.OPENAI, "")
    ApiKeyManager.set_api_key(ApiProvider.ELEVEN_LABS, "")
    ApiKeyManager.set_api_key(ApiProvider.PEXELS, "")

    engine = ContentVideoEnginee()
    #script = engine.read_txt_file("script")
    script = "Welcome to a deep dive into LangChain's latest innovation - RetrievalQA. RetrievalQA plays a crucial role in question-answering technology by enhancing the accuracy and relevance of responses. LangChain has successfully implemented the RetrievalQA chain, utilizing advanced techniques to optimize information retrieval. ARAG in LangChain involves the process of retrieving external data to enhance the content generated by language models. LangChain allows for the modification of retrieved context to improve the quality of information retrieval and analysis. Experience the power of LangChain's RetrievalQA chain in action as we chat with PDF documents for comprehensive insights. As we conclude our exploration, we look towards the future prospects of RetrievalQA technology in LangChain, envisioning an immersive and accessible journey ahead. Thank you for joining us on this journey through the innovative world of LangChain and RetrievalQA. Stay tuned for more exciting developments!"
    engine.generate_content(script)
    #print(script)
